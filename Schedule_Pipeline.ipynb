{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9d5bcb8",
   "metadata": {},
   "source": [
    "run an already published pipeline or a pipeline endpoint on a schedule."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1897ce3",
   "metadata": {},
   "source": [
    "Initialization Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e52a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2045e06c",
   "metadata": {},
   "source": [
    "Compute Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe55692e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "aml_compute_target = \"cpu-cluster\"\n",
    "try:\n",
    "    aml_compute = AmlCompute(ws, aml_compute_target)\n",
    "    print(\"Found existing compute target: {}\".format(aml_compute_target))\n",
    "except ComputeTargetException:\n",
    "    print(\"Creating new compute target: {}\".format(aml_compute_target))\n",
    "    \n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\",\n",
    "                                                                min_nodes = 1, \n",
    "                                                                max_nodes = 4)    \n",
    "    aml_compute = ComputeTarget.create(ws, aml_compute_target, provisioning_config)\n",
    "    aml_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd0003e",
   "metadata": {},
   "source": [
    "### Build and Publish Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c18a1c",
   "metadata": {},
   "source": [
    "Step 1 : Define a pipeline step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ec4562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "source_directory = \"publish_run_train\"\n",
    "\n",
    "trainStep = PythonScriptStep(\n",
    "    name=\"Training_Step\",\n",
    "    script_name=\"train.py\", \n",
    "    compute_target=aml_compute_target, \n",
    "    source_directory=source_directory\n",
    ")\n",
    "print(\"TrainStep created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a70242",
   "metadata": {},
   "source": [
    "Step 2 : Build the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33816ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "pipeline1 = Pipeline(workspace=ws, steps=[trainStep])\n",
    "print (\"Pipeline is built\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c4ac9a",
   "metadata": {},
   "source": [
    "Step 3 : Publish the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41f3e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "timenow = datetime.now().strftime('%m-%d-%Y-%H-%M')\n",
    "\n",
    "pipeline_name = timenow + \"-Pipeline\"\n",
    "print(pipeline_name)\n",
    "\n",
    "published_pipeline1 = pipeline1.publish(\n",
    "    name=pipeline_name, \n",
    "    description=pipeline_name)\n",
    "print(\"Newly published pipeline id: {}\".format(published_pipeline1.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfa7023",
   "metadata": {},
   "source": [
    "Step 4: Create a Pipeline Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865231f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineEndpoint\n",
    "\n",
    "pipeline_endpoint = PipelineEndpoint.publish(workspace=ws, name=\"ScheduledPipelineEndpoint\",\n",
    "                                            pipeline=pipeline1, description=\"Publish pipeline endpoint for schedule test\")\n",
    "pipeline_endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ca655c",
   "metadata": {},
   "source": [
    "### Schedule Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cdbf1b",
   "metadata": {},
   "source": [
    "Schedule operations require id of a published pipeline. You can get all published pipelines and do Schedule operations on them, or if you already know the id of the published pipeline, you can use it directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc58f20",
   "metadata": {},
   "source": [
    "Step 1 : Get published pipeline ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a302c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PublishedPipeline\n",
    "\n",
    "# You could retrieve all pipelines that are published, or \n",
    "# just get the published pipeline object that you have the ID for.\n",
    "\n",
    "# Get all published pipeline objects in the workspace\n",
    "all_pub_pipelines = PublishedPipeline.list(ws)\n",
    "\n",
    "# We will iterate through the list of published pipelines and \n",
    "# use the last ID in the list for Schelue operations: \n",
    "print(\"Published pipelines found in the workspace:\")\n",
    "for pub_pipeline in all_pub_pipelines:\n",
    "    print(pub_pipeline.id)\n",
    "    pub_pipeline_id = pub_pipeline.id\n",
    "\n",
    "print(\"Published pipeline id to be used for Schedule operations: {}\".format(pub_pipeline_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a83a3c0",
   "metadata": {},
   "source": [
    "Step 2 : Create a schedule for the published pipeline using a recurrence.\n",
    "\n",
    "This schedule will run on a specified recurrence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e832b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core.schedule import ScheduleRecurrence, Schedule\n",
    "\n",
    "recurrence = ScheduleRecurrence(frequency=\"Day\", interval=2, hours=[22], minutes=[30]) # Runs every other day at 10:30pm\n",
    "\n",
    "schedule = Schedule.create(workspace=ws, name=\"My_Schedule\",\n",
    "                           pipeline_id=pub_pipeline_id, \n",
    "                           experiment_name='Schedule-run-sample',\n",
    "                           recurrence=recurrence,\n",
    "                           wait_for_provisioning=True,\n",
    "                           description=\"Schedule Run\")\n",
    "\n",
    "print(\"Created schedule with id: {}\".format(schedule.id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eba6656",
   "metadata": {},
   "source": [
    "Step 3 : Get all schedules for a given pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c42afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedules = Schedule.list(ws, pipeline_id=pub_pipeline_id)\n",
    "\n",
    "print(\"Found these schedules for the pipeline id {}:\".format(pub_pipeline_id))\n",
    "for schedule in schedules: \n",
    "    print(schedule.id)\n",
    "    if schedule.recurrence is not None:\n",
    "        schedule_id = schedule.id\n",
    "\n",
    "print(\"Schedule id to be used for schedule operations: {}\".format(schedule_id))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33166707",
   "metadata": {},
   "source": [
    "Step 4 : Get all schedules in your workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f002ae4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedules = Schedule.list(ws, active_only=True) \n",
    "print(\"Your workspace has the following schedules set up:\")\n",
    "for schedule in schedules:\n",
    "    print(\"{} (Published pipeline: {}\".format(schedule.id, schedule.pipeline_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f65914",
   "metadata": {},
   "source": [
    "Step 5 : Get the schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a6614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetched_schedule = Schedule.get(ws, schedule_id)\n",
    "print(\"Using schedule with id: {}\".format(fetched_schedule.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4ffcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case you want to disable the schedule\n",
    "# Set the wait_for_provisioning flag to False if you do not want to wait  \n",
    "# for the call to provision the schedule in the backend.\n",
    "fetched_schedule.disable(wait_for_provisioning=True)\n",
    "fetched_schedule = Schedule.get(ws, schedule_id)\n",
    "print(\"Disabled schedule {}. New status is: {}\".format(fetched_schedule.id, fetched_schedule.status))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c323cce4",
   "metadata": {},
   "source": [
    "### Create a schedule for the pipeline using a Datastore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22afe2dd",
   "metadata": {},
   "source": [
    "This schedule will run when additions or modifications are made to Blobs in the Datastore. By default, the Datastore container is monitored for changes. Use the path_on_datastore parameter to instead specify a path on the Datastore to monitor for changes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7950e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.datastore import Datastore\n",
    "\n",
    "datastore = Datastore(workspace=ws, name=\"workspaceblobstore\")\n",
    "\n",
    "schedule = Schedule.create(workspace=ws, name=\"My_Schedule\",\n",
    "                           pipeline_id=pub_pipeline_id, \n",
    "                           experiment_name='Schedule-run-sample',\n",
    "                           datastore=datastore,\n",
    "                           wait_for_provisioning=True,\n",
    "                           description=\"Schedule Run\")\n",
    "                          #polling_interval=5, use polling_interval to specify how often to poll for blob additions/modifications. Default value is 5 minutes.\n",
    "                          #path_on_datastore=\"file/path\") use path_on_datastore to specify a specific folder to monitor for changes.\n",
    "        \n",
    "        \n",
    "print(\"Created schedule with id: {}\".format(schedule.id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac06562",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
