{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41b2846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import the configuration notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a513cffd",
   "metadata": {},
   "source": [
    "#### Import the modules required to work\n",
    "workspace , experiment , datastore , RunDetails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd773f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment, Datastore\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "print(\"azure-ML SKD version :\" azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6027643f",
   "metadata": {},
   "source": [
    "#### Import Pipeline modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23958e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.pipeline.steps import PythonScriptStep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5787ea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Workspace using configuration notebook\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name , ws.resource_group , ws.location , ws.subscription_id , sep ='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6605152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a default datastore\n",
    "def_blob_store = ws.get_default_datastore()\n",
    "def_blob_store = Datastore(ws , \"workspaceblobstore\")\n",
    "#workspaceblobstore this must be used as is\n",
    "print(\"Name of blobstore : {}\".format(def_blob_store.name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ea515a",
   "metadata": {},
   "source": [
    "#### Uploading data to default datastore (Az file storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32d1d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def_blob_store.upload_files([\"./20news.pkl\"] , target_path = \"20newsgroups\" , overwrite = True)\n",
    "print(\"Upload is now done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c9b3f1",
   "metadata": {},
   "source": [
    "#### Compute targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e908db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all available compute targets in your workspace\n",
    "\n",
    "cts = ws.compute_targets\n",
    "for i in cts:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1714fd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrive an existing compute or create a new compute \n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "aml_compute_target = \"cpu-cluster\"\n",
    "try:\n",
    "    aml_compute = AmlCompute(ws, aml_compute_target)\n",
    "    print(\"found existing compute target.\")\n",
    "except ComputeTargetException:\n",
    "    print(\"creating new compute target\")\n",
    "    \n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\",\n",
    "                                                                min_nodes = 1, \n",
    "                                                                max_nodes = 4)    \n",
    "    aml_compute = ComputeTarget.create(ws, aml_compute_target, provisioning_config)\n",
    "    aml_compute.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "print(\"Azure Machine Learning Compute attached\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314c037e",
   "metadata": {},
   "source": [
    "### Creating a step in Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e19172",
   "metadata": {},
   "source": [
    "A Step is a unit of execution. Step typically needs a target of execution (compute target), a script to execute, and may require script arguments and inputs, and can produce outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3217ed",
   "metadata": {},
   "source": [
    "Ensure to have a separate folder for scripts and dependencies and give this directory as source directory to avoid re run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134675af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create PythonScriptStep\n",
    "\n",
    "source_directory = './train'\n",
    "print('Source directory for step is : {}'.format(os.path.realpath(source_directory)))\n",
    "\n",
    "step1 = PythonScriptStep(name=\"train_step\" , script_name=\"train.py\", \n",
    "                         compute_target=aml_compute,\n",
    "                        source_directory=source_directory,\n",
    "                        allow_reuse=True)\n",
    "print(\"Step1 creation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636e736b",
   "metadata": {},
   "source": [
    "#### Run multiple steps in parallel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a719f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new source directory\n",
    "\n",
    "source_directory = './compare'\n",
    "print('Source directory for step is: {}'.format(os.path.realpath(source_directory)))\n",
    "\n",
    "# define step\n",
    "\n",
    "step2 = PythonScriptStep(name=\"compare_step\",\n",
    "                        script_name=\"compare.py\",\n",
    "                         compute_target=aml_compute,\n",
    "                         source_directory=source_directory)\n",
    "\n",
    "# Use RunConfiguration to create conda dependencies and their # respective environments\n",
    "# https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.runconfiguration?view=azure-ml-py\n",
    "\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "\n",
    "# create new run config object \n",
    "\n",
    "run_config = RunConfiguration()\n",
    "\n",
    "# enable docker runtime\n",
    "run_config.environment.docker.enabled = True\n",
    "\n",
    "# set docker image to default CPU image \n",
    "run_config.environment.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "\n",
    "# use conda_dependencies.yml to create a conda environment in the Docker image for execution\n",
    "run_config.environment.python.user_managed_dependencies = False\n",
    "\n",
    "\n",
    "# now give dependencies for conda which you created above\n",
    "# for scikit-learn\n",
    "\n",
    "run_config.environment.python.conda_dependencies = CondaDependencies.create(conda_packages=['scikit-learn'])\n",
    "\n",
    "# Now again a new source directory \n",
    "\n",
    "source_directory = './extract'\n",
    "print('Source directory for this step is : {}'.format(os.path.realpath(source_directory)))\n",
    "\n",
    "# create a new step\n",
    "\n",
    "step3 = PythonScriptStep(name=\"extract_step\",\n",
    "                        script_name=\"extract.py\",\n",
    "                        compute_target=aml_compute,\n",
    "                        source_directory=source_directory,\n",
    "                        runconfig=run_config)\n",
    "\n",
    "# now list of steps to be run\n",
    "\n",
    "steps = [step1,step2,step3]\n",
    "print(\"Step lists done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789a9794",
   "metadata": {},
   "source": [
    "### Building the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580d4660",
   "metadata": {},
   "source": [
    "All steps run in parallel once we submit.When submit is called, a PipelineRun is created which in turn creates StepRun objects for each step in the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a998ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new pipeline\n",
    "\n",
    "pipeline1 = Pipeline(workspace=ws, steps=steps)\n",
    "print(\"Pipeline is created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8513bdee",
   "metadata": {},
   "source": [
    "#### VAlidate the pipeline built in last step before submitting it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355e0eb3",
   "metadata": {},
   "source": [
    "runs validation steps such as checking for circular dependencies and parameter checks etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb70f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline1.validate()\n",
    "print(\"Pipeline validation completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1c19b0",
   "metadata": {},
   "source": [
    "### Submit the Pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8e7cfa",
   "metadata": {},
   "source": [
    "involves creating an Experiment object and providing the built pipeline for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c311388",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_run1 = Experiment(ws, 'Hello_world').submit(pipeline1, regenerate_outputs=False)\n",
    "print(\"Pipeline is submitted for execution!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83db3bb8",
   "metadata": {},
   "source": [
    "#### Examine the pipeline run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b755b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use RunDetails Widget\n",
    "\n",
    "runDetails(pipeline_run1).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a38c268",
   "metadata": {},
   "source": [
    "Job logs , metric , stdout , stderr files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6978f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_runs = pipeline_run1.get_children()\n",
    "for i in step_runs:\n",
    "    status = step_run.get_status()\n",
    "    print('Script :' , i.name , 'status :',status)\n",
    "    \n",
    "    # if job is failing then get the details as:\n",
    "    if status ==\"Failed\":\n",
    "        joblog = i.get_job_log()\n",
    "        print('job log :' , joblog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6511a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
